name: CI (dev)

on:
  push:
    branches: [feat-*, copilot/*]
    paths:
        - 'docker/Dockerfile.training'
        - '.github/workflows/ci-dev.yml'
        - 'r/**'
        - 'app/**'
        - 'docker/training_entrypoint.sh'
        - '!docker/Dockerfile.training-base'
        - 'infra/terraform/**'  # exclude base so normal builds skip base

permissions:
  id-token: write
  contents: read

jobs:
  ci:
    runs-on: ubuntu-latest
    env:
      PROJECT_ID: datawarehouse-422511
      PROJECT_NUMBER: "321233323695"
      REGION: europe-west1
      ARTIFACT_REPO: mmm-repo
      WEB_IMAGE: mmm-web
      TRAINING_IMAGE: mmm-training
      SERVICE_NAME: mmm-app-dev
      BUCKET: mmm-app-output
      WIF_POOL: github-pool
      WIF_PROVIDER: github-oidc
      SA_EMAIL: github-deployer@datawarehouse-422511.iam.gserviceaccount.com
      WEB_RUNTIME_SA: mmm-web-service-sa@datawarehouse-422511.iam.gserviceaccount.com
      TRAINING_RUNTIME_SA: mmm-training-job-sa@datawarehouse-422511.iam.gserviceaccount.com
      TF_PLUGIN_CACHE_DIR: ~/.terraform.d/plugin-cache
      # TF_VAR_* for sensitive/default vars (preferred over -var flags)
      TF_VAR_sf_private_key: ${{ secrets.SF_PRIVATE_KEY }}
      TF_VAR_auth_client_id: ${{ secrets.GOOGLE_OAUTH_CLIENT_ID }}
      TF_VAR_auth_client_secret: ${{ secrets.GOOGLE_OAUTH_CLIENT_SECRET }}
      TF_VAR_auth_cookie_secret: ${{ secrets.STREAMLIT_COOKIE_SECRET }}
      TF_VAR_scheduler_job_name: robyn-queue-tick-dev
      TF_VAR_queue_name: default-dev
      # ... (add other non-sensitive TF_VAR_* if needed from dev.tfvars)

    steps:
      - uses: actions/checkout@v4

      - name: Auth to Google (OIDC)
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/${{ env.PROJECT_NUMBER }}/locations/global/workloadIdentityPools/${{ env.WIF_POOL }}/providers/${{ env.WIF_PROVIDER }}
          service_account: ${{ env.SA_EMAIL }}

      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2

      - name: Configure Docker auth for Artifact Registry
        run: gcloud auth configure-docker ${{ env.REGION }}-docker.pkg.dev --quiet

      - name: Compute image tags and URLs
        shell: bash
        run: |
          echo "IMG_TAG=${{ github.sha }}" >> "$GITHUB_ENV"

          # Web service image
          echo "WEB_IMAGE_URL=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/${{ env.WEB_IMAGE }}:${{ github.sha }}" >> "$GITHUB_ENV"
          echo "WEB_IMAGE_URL_LATEST=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/${{ env.WEB_IMAGE }}:latest" >> "$GITHUB_ENV"

          # Training job image
          echo "TRAINING_IMAGE_URL=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/${{ env.TRAINING_IMAGE }}:${{ github.sha }}" >> "$GITHUB_ENV"
          echo "TRAINING_IMAGE_URL_LATEST=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/${{ env.TRAINING_IMAGE }}:latest" >> "$GITHUB_ENV"

      - name: Set up QEMU (multi-arch)
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build & Push web service image
        id: build_web
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./docker/Dockerfile.web
          platforms: linux/amd64
          push: true
          build-args: |
            GIT_SHA=${{ github.sha }}
          tags: |
            ${{ env.WEB_IMAGE_URL }}
            ${{ env.WEB_IMAGE_URL_LATEST }}
          cache-from: type=gha,scope=mmm-web-${{ github.ref_name }}
          cache-to: type=gha,mode=max,scope=mmm-web-${{ github.ref_name }}
      - name: Build & Push training-base
        id: build_training_base
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./docker/Dockerfile.training-base
          platforms: linux/amd64
          push: true
          tags: ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/mmm-training-base:latest
          cache-from: |
            type=registry,ref=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/mmm-training-base:buildcache
          cache-to: |
            type=registry,ref=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/mmm-training-base:buildcache,mode=max

      - name: Build & Push training job image
        id: build_training
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./docker/Dockerfile.training
          build-args: |
            BASE_REF=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/mmm-training-base:latest
          platforms: linux/amd64
          push: true
          tags: |
            ${{ env.TRAINING_IMAGE_URL }}
            ${{ env.TRAINING_IMAGE_URL_LATEST }}
          cache-from: |
            type=registry,ref=${{ env.TRAINING_IMAGE_URL_LATEST }}
            type=registry,ref=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/${{ env.TRAINING_IMAGE }}:buildcache
          cache-to: |
            type=registry,ref=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/${{ env.TRAINING_IMAGE }}:buildcache,mode=max

      - name: Setup Python for tests
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Run unit tests
        shell: bash
        run: |
          echo "Running unit tests for single job run functionality..."
          python3 -m unittest tests.test_single_job_config -v

      - name: Compute digest-pinned image refs
        shell: bash
        run: |
          # docker/build-push-action exposes the built manifest digest as outputs.digest (e.g. "sha256:abcd...")
          echo "WEB_IMAGE_DIGEST=${{ steps.build_web.outputs.digest }}" >> "$GITHUB_ENV"
          echo "TRAINING_IMAGE_DIGEST=${{ steps.build_training.outputs.digest }}" >> "$GITHUB_ENV"

          echo "WEB_IMAGE_REF=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/${{ env.WEB_IMAGE }}@${{ steps.build_web.outputs.digest }}" >> "$GITHUB_ENV"
          echo "TRAINING_IMAGE_REF=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/${{ env.TRAINING_IMAGE }}@${{ steps.build_training.outputs.digest }}" >> "$GITHUB_ENV"

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.9.0
          terraform_wrapper: false

      - name: Configure Terraform plugin cache
        shell: bash
        run: |
          set -euo pipefail
          CACHE_DIR="$RUNNER_TOOL_CACHE/terraform-plugins"
          mkdir -p "$CACHE_DIR"
          echo "TF_PLUGIN_CACHE_DIR=$CACHE_DIR" >> "$GITHUB_ENV"


      - name: Terraform init / validate
        working-directory: infra/terraform
        env:
          TF_IN_AUTOMATION: "true"
        run: |
          terraform init -input=false -reconfigure -backend-config="prefix=envs/dev"
          terraform -version
          terraform workspace new dev || terraform workspace select dev  # Create/select if needed
          terraform fmt -check
          terraform validate

      - name: Import existing resources if needed
        working-directory: infra/terraform
        shell: bash
        run: |
          set -euo pipefail
          # Import sf-private-key if exists and not already managed
          if gcloud secrets describe sf-private-key --project=$PROJECT_ID >/dev/null 2>&1; then
            echo "Checking if sf-private-key is already managed..."
            if ! terraform state show google_secret_manager_secret.sf_private_key >/dev/null 2>&1; then
              echo "Importing sf-private-key secret..."
              terraform import google_secret_manager_secret.sf_private_key projects/$PROJECT_ID/secrets/sf-private-key || true
            else
              echo "sf-private-key already managed in Terraform stateâ€”skipping import."
            fi
            VERSION_ID=$(gcloud secrets versions list sf-private-key --project=$PROJECT_ID --limit=1 --format="value(name.basename())")
            if [ -n "$VERSION_ID" ]; then
              echo "Checking if sf-private-key version is already managed..."
              if ! terraform state show google_secret_manager_secret_version.sf_private_key_version >/dev/null 2>&1; then
                echo "Importing sf-private-key version $VERSION_ID..."
                terraform import google_secret_manager_secret_version.sf_private_key_version projects/$PROJECT_ID/secrets/sf-private-key/versions/$VERSION_ID || true
              else
                echo "sf-private-key version already managed in Terraform stateâ€”skipping import."
              fi
            fi
          else
            echo "sf-private-key does not exist yetâ€”will create on apply."
          fi
          # Import sf-private-key-persistent if exists and not already managed
          if gcloud secrets describe sf-private-key-persistent --project=$PROJECT_ID >/dev/null 2>&1; then
            echo "Checking if sf-private-key-persistent is already managed..."
            if ! terraform state show google_secret_manager_secret.sf_private_key_persistent >/dev/null 2>&1; then
              echo "Importing sf-private-key-persistent secret..."
              terraform import google_secret_manager_secret.sf_private_key_persistent projects/$PROJECT_ID/secrets/sf-private-key-persistent || true
            else
              echo "sf-private-key-persistent already managed in Terraform stateâ€”skipping import."
            fi
          else
            echo "sf-private-key-persistent does not exist yetâ€”will create on apply."
          fi
          # Import SAs (existing)
          if ! terraform state show google_service_account.web_service_sa >/dev/null 2>&1; then
            terraform import google_service_account.web_service_sa "projects/$PROJECT_ID/serviceAccounts/$WEB_RUNTIME_SA" || true
          else
            echo "web_service_sa already managed in Terraform stateâ€”skipping import."
          fi
          if ! terraform state show google_service_account.scheduler >/dev/null 2>&1; then
            terraform import google_service_account.scheduler \
              "projects/$PROJECT_ID/serviceAccounts/robyn-queue-scheduler@$PROJECT_ID.iam.gserviceaccount.com" || true
          else
            echo "scheduler already managed in Terraform stateâ€”skipping import."
          fi
          if ! terraform state show google_service_account.training_job_sa >/dev/null 2>&1; then
            terraform import google_service_account.training_job_sa "projects/$PROJECT_ID/serviceAccounts/$TRAINING_RUNTIME_SA" || true
          else
            echo "training_job_sa already managed in Terraform stateâ€”skipping import."
          fi
          # Import training job
          if gcloud run jobs describe ${SERVICE_NAME}-training --region=$REGION --project=$PROJECT_ID >/dev/null 2>&1; then
            echo "Checking if training job is already managed..."
            if ! terraform state show google_cloud_run_v2_job.training_job >/dev/null 2>&1; then
              echo "Training job existsâ€”importing..."
              terraform import google_cloud_run_v2_job.training_job projects/$PROJECT_ID/locations/$REGION/jobs/${SERVICE_NAME}-training || true
            else
              echo "Training job already managed in Terraform stateâ€”skipping import."
            fi
          else
            echo "Training job does not existâ€”will create on apply."
          fi
          # Import web service
          if gcloud run services describe ${SERVICE_NAME}-web --region=$REGION --project=$PROJECT_ID >/dev/null 2>&1; then
            echo "Checking if web service is already managed..."
            if ! terraform state show google_cloud_run_service.web_service >/dev/null 2>&1; then
              echo "Web service existsâ€”importing..."
              terraform import google_cloud_run_service.web_service projects/$PROJECT_ID/locations/$REGION/services/${SERVICE_NAME}-web || true
            else
              echo "Web service already managed in Terraform stateâ€”skipping import."
            fi
          else
            echo "Web service does not existâ€”will create on apply."
          fi

      - name: Clear taint & disable deletion protection
        working-directory: infra/terraform
        shell: bash
        env:
          PROJECT_ID: ${{ env.PROJECT_ID }}
          REGION: ${{ env.REGION }}
          SERVICE_NAME: ${{ env.SERVICE_NAME }}
        run: |
          set -euo pipefail

          # Disable deletion protection on web service if it exists
          echo "Disabling Cloud Run deletion protection..."
          if gcloud run services describe "${SERVICE_NAME}-web" --region="$REGION" --project="$PROJECT_ID" >/dev/null 2>&1; then
            gcloud run services update "${SERVICE_NAME}-web" \
              --region="$REGION" \
              --clear-deletion-protection || true
          else
            echo "Web service does not existâ€”skipping deletion protection update."
          fi

          # Clear taints on Terraform resources
          echo "Clearing Terraform taints..."
          if terraform -version | grep -qE '^Terraform v1\.'; then
            if terraform state show google_cloud_run_service.web_service >/dev/null 2>&1; then
              terraform untaint google_cloud_run_service.web_service || true
            else
              echo "Web service not in stateâ€”skipping untaint."
            fi
            if terraform state show google_cloud_run_v2_job.training_job >/dev/null 2>&1; then
              terraform untaint google_cloud_run_v2_job.training_job || true
            else
              echo "Training job not in stateâ€”skipping untaint."
            fi
          fi

          # Re-import if still tainted
          if terraform plan -refresh-only -no-color 2>&1 | grep -q "is tainted"; then
            echo "Re-importing resources to clear taints..."
            if gcloud run services describe "${SERVICE_NAME}-web" --region="$REGION" --project="$PROJECT_ID" >/dev/null 2>&1; then
              terraform state rm google_cloud_run_service.web_service || true
              terraform import google_cloud_run_service.web_service \
                "projects/$PROJECT_ID/locations/$REGION/services/${SERVICE_NAME}-web" || true
            fi
            if gcloud run jobs describe "${SERVICE_NAME}-training" --region="$REGION" --project="$PROJECT_ID" >/dev/null 2>&1; then
              terraform state rm google_cloud_run_v2_job.training_job || true
              terraform import google_cloud_run_v2_job.training_job \
                "projects/$PROJECT_ID/locations/$REGION/jobs/${SERVICE_NAME}-training" || true
            fi
          fi

      - name: Terraform plan
        working-directory: infra/terraform
        env:
          TF_IN_AUTOMATION: "true"
          TF_VAR_project_id: $PROJECT_ID
          TF_VAR_region: $REGION
          TF_VAR_service_name: $SERVICE_NAME
          TF_VAR_bucket_name: $BUCKET
          TF_VAR_deployer_sa: $SA_EMAIL
          # ðŸ‘‡ use digest-pinned refs here
          TF_VAR_web_image: ${{ env.WEB_IMAGE_REF }}
          TF_VAR_training_image: ${{ env.TRAINING_IMAGE_REF }}
        run: |
          echo "Deploying images (digest pinned):"
          echo "  Web service: $WEB_IMAGE_REF"
          echo "  Training job: $TRAINING_IMAGE_REF"

          terraform plan -input=false -var-file="envs/dev.tfvars" -out=tfplan

      - name: Terraform apply
        working-directory: infra/terraform
        env:
          TF_IN_AUTOMATION: "true"
          TF_VAR_project_id: $PROJECT_ID
          TF_VAR_region: $REGION
          TF_VAR_service_name: $SERVICE_NAME
          TF_VAR_bucket_name: $BUCKET
          TF_VAR_deployer_sa: $SA_EMAIL
          TF_VAR_web_image: ${{ env.WEB_IMAGE_REF }}
          TF_VAR_training_image: ${{ env.TRAINING_IMAGE_REF }}
        run: terraform apply -input=false -auto-approve tfplan
      - name: Print deployment info
        working-directory: infra/terraform
        run: |
          echo "Deployment completed successfully!"
          echo ""
          echo "Web Service URL:"
          terraform output web_service_url
          echo ""
          echo "Training Job Name:"
          terraform output training_job_name
          echo ""
          echo "Architecture:"
          echo "  - Web Interface: Cloud Run Service (2 CPUs, 4GB)"
          echo "  - Training Jobs: Cloud Run Jobs (up to 32 CPUs, 128GB)"
          echo "  - Storage: GCS Bucket ($BUCKET)"
