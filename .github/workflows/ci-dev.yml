name: CI (dev)

on:
  push:
    branches: [feat-*]

permissions:
  id-token: write
  contents: read

jobs:
  ci:
    runs-on: ubuntu-latest
    env:
      PROJECT_ID: datawarehouse-422511
      PROJECT_NUMBER: "321233323695"
      REGION: europe-west1
      ARTIFACT_REPO: mmm-repo
      WEB_IMAGE: mmm-web
      TRAINING_IMAGE: mmm-training
      SERVICE_NAME: mmm-app-dev
      BUCKET: mmm-app-output
      WIF_POOL: github-pool
      WIF_PROVIDER: github-oidc
      SA_EMAIL: github-deployer@datawarehouse-422511.iam.gserviceaccount.com
      WEB_RUNTIME_SA: mmm-web-service-sa@datawarehouse-422511.iam.gserviceaccount.com
      TRAINING_RUNTIME_SA: mmm-training-job-sa@datawarehouse-422511.iam.gserviceaccount.com
      TF_PLUGIN_CACHE_DIR: ~/.terraform.d/plugin-cache
      # TF_VAR_* for sensitive/default vars (preferred over -var flags)
      TF_VAR_sf_private_key: ${{ secrets.SF_PRIVATE_KEY }}
      TF_VAR_scheduler_job_name: robyn-queue-tick-dev
      TF_VAR_queue_name: default-dev
      # ... (add other non-sensitive TF_VAR_* if needed from dev.tfvars)

    steps:
      - uses: actions/checkout@v4

      - name: Auth to Google (OIDC)
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/${{ env.PROJECT_NUMBER }}/locations/global/workloadIdentityPools/${{ env.WIF_POOL }}/providers/${{ env.WIF_PROVIDER }}
          service_account: ${{ env.SA_EMAIL }}

      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2

      - name: Configure Docker auth for Artifact Registry
        run: gcloud auth configure-docker ${{ env.REGION }}-docker.pkg.dev --quiet

      - name: Compute image tags and URLs
        shell: bash
        run: |
          echo "IMG_TAG=${{ github.sha }}" >> "$GITHUB_ENV"

          # Web service image
          echo "WEB_IMAGE_URL=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/${{ env.WEB_IMAGE }}:${{ github.sha }}" >> "$GITHUB_ENV"
          echo "WEB_IMAGE_URL_LATEST=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/${{ env.WEB_IMAGE }}:latest" >> "$GITHUB_ENV"

          # Training job image
          echo "TRAINING_IMAGE_URL=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/${{ env.TRAINING_IMAGE }}:${{ github.sha }}" >> "$GITHUB_ENV"
          echo "TRAINING_IMAGE_URL_LATEST=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/${{ env.TRAINING_IMAGE }}:latest" >> "$GITHUB_ENV"

      - name: Set up QEMU (multi-arch)
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build & Push web service image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./docker/Dockerfile.web
          platforms: linux/amd64
          push: true
          tags: |
            ${{ env.WEB_IMAGE_URL }}
            ${{ env.WEB_IMAGE_URL_LATEST }}
          cache-from: type=gha,scope=mmm-web
          cache-to: type=gha,mode=max,scope=mmm-web

      - name: Build & Push training job image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./docker/Dockerfile.training
          platforms: linux/amd64
          push: true
          tags: |
            ${{ env.TRAINING_IMAGE_URL }}
            ${{ env.TRAINING_IMAGE_URL_LATEST }}
          cache-from: type=gha,scope=mmm-training
          cache-to: type=gha,mode=max,scope=mmm-training

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.13.0
          terraform_wrapper: false

      - name: Configure Terraform plugin cache
        shell: bash
        run: |
          set -euo pipefail
          CACHE_DIR="$RUNNER_TOOL_CACHE/terraform-plugins"
          mkdir -p "$CACHE_DIR"
          echo "TF_PLUGIN_CACHE_DIR=$CACHE_DIR" >> "$GITHUB_ENV"


      - name: Terraform init / validate
        working-directory: infra/terraform
        env:
          TF_IN_AUTOMATION: "true"
        run: |
          terraform init -input=false -reconfigure -backend-config="prefix=envs/dev"
          terraform -version
          terraform workspace new dev || terraform workspace select dev  # Create/select if needed
          terraform fmt -check
          terraform validate

      - name: Import existing resources if needed
        working-directory: infra/terraform
        shell: bash
        run: |
          set -euo pipefail

          # Import sf-private-key if exists
          if gcloud secrets describe sf-private-key --project=$PROJECT_ID >/dev/null 2>&1; then
            echo "Importing sf-private-key secret..."
            terraform import google_secret_manager_secret.sf_private_key projects/$PROJECT_ID/secrets/sf-private-key || true

            VERSION_ID=$(gcloud secrets versions list sf-private-key --project=$PROJECT_ID --limit=1 --format="value(name.basename())")
            if [ -n "$VERSION_ID" ]; then
              echo "Importing sf-private-key version $VERSION_ID..."
              terraform import 'google_secret_manager_secret_version.sf_private_key_version[0]' projects/$PROJECT_ID/secrets/sf-private-key/$VERSION_ID || true
            fi
          else
            echo "sf-private-key does not exist yet—will create on apply."
          fi

          # Import SAs (existing)
          terraform state show google_service_account.web_service_sa >/dev/null 2>&1 || \
          terraform import google_service_account.web_service_sa "projects/$PROJECT_ID/serviceAccounts/$WEB_RUNTIME_SA" || true

          terraform state show google_service_account.scheduler >/dev/null 2>&1 || \
          terraform import google_service_account.scheduler \
            "projects/$PROJECT_ID/serviceAccounts/robyn-queue-scheduler@$PROJECT_ID.iam.gserviceaccount.com" || true

          terraform state show google_service_account.training_job_sa >/dev/null 2>&1 || \
          terraform import google_service_account.training_job_sa "projects/$PROJECT_ID/serviceAccounts/$TRAINING_RUNTIME_SA" || true

          # Import training job (ENHANCED: Force describe + import with logging)
          echo "Checking for existing training job..."
          if gcloud run jobs describe ${SERVICE_NAME}-training --region=$REGION --project=$PROJECT_ID >/dev/null 2>&1; then
            echo "Training job exists—importing..."
            terraform import google_cloud_run_v2_job.training_job projects/$PROJECT_ID/locations/$REGION/jobs/${SERVICE_NAME}-training || true
            # Force refresh after import
            terraform refresh -target=google_cloud_run_v2_job.training_job || true
          else
            echo "Training job does not exist—will create on apply."
          fi

          # Import web service if exists (for completeness)
          if gcloud run services describe ${SERVICE_NAME}-web --region=$REGION --project=$PROJECT_ID >/dev/null 2>&1; then
            echo "Web service exists—importing..."
            terraform import google_cloud_run_service.web_service projects/$PROJECT_ID/locations/$REGION/services/${SERVICE_NAME}-web || true
            terraform refresh -target=google_cloud_run_service.web_service || true
          else
            echo "Web service does not exist—will create on apply."
          fi
      - name: Clear taint & disable deletion protection
        working-directory: infra/terraform
        shell: bash
        env:
          PROJECT_ID: ${{ env.PROJECT_ID }}
          REGION: ${{ env.REGION }}
          SERVICE_NAME: ${{ env.SERVICE_NAME }}
        run: |
          set -euo pipefail

          # Disable deletion protection on web service (FIX: Only for services, not jobs)
          echo "Disabling Cloud Run deletion protection..."
          gcloud run services update "${SERVICE_NAME}-web" \
            --region="$REGION" \
            --no-deletion-protection || true

          # Clear taints on Terraform resources
          echo "Clearing Terraform taints..."
          if terraform -version | grep -qE '^Terraform v1\.'; then
            terraform untaint google_cloud_run_service.web_service || true
            terraform untaint google_cloud_run_v2_job.training_job || true
          fi

          # Re-import if still tainted
          if terraform plan -refresh-only -no-color 2>&1 | grep -q "is tainted"; then
            echo "Re-importing resources to clear taints..."

            # Re-import web service
            terraform state rm google_cloud_run_service.web_service || true
            terraform import google_cloud_run_service.web_service \
              "projects/$PROJECT_ID/locations/$REGION/services/${SERVICE_NAME}-web" || true

            # Re-import training job
            terraform state rm google_cloud_run_v2_job.training_job || true
            terraform import google_cloud_run_v2_job.training_job \
              "projects/$PROJECT_ID/locations/$REGION/jobs/${SERVICE_NAME}-training" || true
          fi

      - name: Terraform plan
        working-directory: infra/terraform
        env:
          TF_IN_AUTOMATION: "true"
          # Remove -var flags; use TF_VAR_* env vars only (set above)
          TF_VAR_project_id: $PROJECT_ID
          TF_VAR_region: $REGION
          TF_VAR_service_name: $SERVICE_NAME
          TF_VAR_bucket_name: $BUCKET
          TF_VAR_deployer_sa: $SA_EMAIL
          TF_VAR_web_image: $WEB_IMAGE_URL
          TF_VAR_training_image: $TRAINING_IMAGE_URL
          # scheduler/queue from env (set above)
        run: |
          echo "Deploying images:"
          echo "  Web service: $WEB_IMAGE_URL"
          echo "  Training job: $TRAINING_IMAGE_URL"

          terraform plan -input=false \
            -var-file="envs/dev.tfvars" \
            -out=tfplan  # No -var flags needed

      - name: Terraform apply
        working-directory: infra/terraform
        env:
          TF_IN_AUTOMATION: "true"
          # Same TF_VAR_* as plan
        run: terraform apply -input=false -auto-approve tfplan

      - name: Print deployment info
        working-directory: infra/terraform
        run: |
          echo "Deployment completed successfully!"
          echo ""
          echo "Web Service URL:"
          terraform output web_service_url
          echo ""
          echo "Training Job Name:"
          terraform output training_job_name
          echo ""
          echo "Architecture:"
          echo "  - Web Interface: Cloud Run Service (2 CPUs, 4GB)"
          echo "  - Training Jobs: Cloud Run Jobs (up to 32 CPUs, 128GB)"
          echo "  - Storage: GCS Bucket ($BUCKET)"
